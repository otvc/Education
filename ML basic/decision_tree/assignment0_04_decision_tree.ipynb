{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## assignment 04: Decision Tree construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If working in colab, uncomment the following line\n",
    "# ! wget https://raw.githubusercontent.com/girafe-ai/ml-mipt/21f_made/homeworks/assignment0_04_tree/tree.py -nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.datasets import make_classification, make_regression, load_digits, load_boston\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix the `random_state` (a.k.a. random seed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True]\n",
      " [False  True]\n",
      " [ True False]]\n",
      "[ True False False]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects  = np.array([[1, 2,],\n",
    "                     [3, 1],\n",
    "                     [1, 5]])\n",
    "pred = np.zeros((objects.shape[0], 1))\n",
    "threshold = 2\n",
    "index = 0\n",
    "t = objects[:] <= 2\n",
    "mask = np.logical_and(t, False)\n",
    "print(t)\n",
    "print(t.sum(axis = -1) == t.shape[-1])\n",
    "pred[t.sum(axis = -1) == t.shape[-1]] = 2\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_cls = np.array([[0, 1],\n",
    "                       [0, 1]])\n",
    "classes = np.unique(unique_cls, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3]), array([1, 2, 1], dtype=int64))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([[1, 2], [3, 2]], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n",
      "2\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "a = [1]\n",
    "a.append(2)\n",
    "print(a)\n",
    "print(a.pop())\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your ultimate task for today is to impement the `DecisionTree` class and use it to solve classification and regression problems.__\n",
    "\n",
    "__Specifications:__\n",
    "- The class inherits from `sklearn.BaseEstimator`;\n",
    "- Constructor is implemented for you. It has the following parameters:\n",
    "    * `max_depth` - maximum depth of the tree; `np.inf` by default\n",
    "    * `min_samples_split` - minimal number of samples in the leaf to make a split; `2` by default;\n",
    "    * `criterion` - criterion to select the best split; in classification one of `['gini', 'entropy']`, default `gini`; in regression `variance`;\n",
    "\n",
    "- `fit` method takes `X` (`numpy.array` of type `float` shaped `(n_objects, n_features)`) and `y` (`numpy.array` of type float shaped `(n_objects, 1)` in regression; `numpy.array` of type int shaped `(n_objects, 1)` with class labels in classification). It works inplace and fits the `DecisionTree` class instance to the provided data from scratch.\n",
    "\n",
    "- `predict` method takes `X` (`numpy.array` of type `float` shaped `(n_objects, n_features)`) and returns the predicted $\\hat{y}$ values. In classification it is a class label for every object (the most frequent in the leaf; if several classes meet this requirement select the one with the smallest class index). In regression it is the desired constant (e.g. mean value for `variance` criterion)\n",
    "\n",
    "- `predict_proba` method (works only for classification (`gini` or `entropy` criterion). It takes `X` (`numpy.array` of type `float` shaped `(n_objects, n_features)`) and returns the `numpy.array` of type `float` shaped `(n_objects, n_features)` with class probabilities for every object from `X`. Class $i$ probability equals the ratio of $i$ class objects that got in this node in the training set.\n",
    "\n",
    "    \n",
    "__Small recap:__\n",
    "\n",
    "To find the optimal split the following functional is evaluated:\n",
    "    \n",
    "$$G(j, t) = H(Q) - \\dfrac{|L|}{|Q|} H(L) - \\dfrac{|R|}{|Q|} H(R),$$\n",
    "    where $Q$ is the dataset from the current node, $L$ and $R$ are left and right subsets defined by the split $x^{(j)} < t$.\n",
    "\n",
    "\n",
    "\n",
    "1. Classification. Let $p_i$ be the probability of $i$ class in subset $X$ (ratio of the $i$ class objects in the dataset). The criterions are defined as:\n",
    "    \n",
    "    * `gini`: Gini impurity $$H(R) = 1 -\\sum_{i = 1}^K p_i^2$$\n",
    "    \n",
    "    * `entropy`: Entropy $$H(R) = -\\sum_{i = 1}^K p_i \\log(p_i)$$ (One might use the natural logarithm).\n",
    "    \n",
    "2. Regression. Let $y_l$ be the target value for the $R$, $\\mathbf{y} = (y_1, \\dots, y_N)$ â€“ all targets for the selected dataset $X$.\n",
    "    \n",
    "    * `variance`: $$H(R) = \\dfrac{1}{|R|} \\sum_{y_j \\in R}(y_j - \\text{mean}(\\mathbf{y}))^2$$\n",
    "    \n",
    "    * `mad_median`: $$H(R) = \\dfrac{1}{|R|} \\sum_{y_j \\in R}|y_j - \\text{median}(\\mathbf{y})|$$\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hints and comments**:\n",
    "\n",
    "* No need to deal with categorical features, they will not be present.\n",
    "* Siple greedy recursive procedure is enough. However, you can speed it up somehow (e.g. using percentiles).\n",
    "* Please, do not copy implementations available online. You are supposed to build very simple example of the Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File `tree.py` is waiting for you. Implement all the needed methods in that file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree import entropy, gini, variance, mad_median, DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.ones((4, 5), dtype=float) * np.arange(4)[:, None]\n",
    "y = np.arange(4)[:, None] + np.asarray([0.2, -0.3, 0.1, 0.4])[:, None]\n",
    "class_estimator = DecisionTree(max_depth=10, criterion_name='gini')\n",
    "\n",
    "(X_l, y_l), (X_r, y_r) = class_estimator.make_split(1, 1., X, y)\n",
    "\n",
    "assert np.array_equal(X[:1], X_l)\n",
    "assert np.array_equal(X[1:], X_r)\n",
    "assert np.array_equal(y[:1], y_l)\n",
    "assert np.array_equal(y[1:], y_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_data = load_digits().data\n",
    "digits_target = load_digits().target[:, None] # to make the targets consistent with our model interfaces\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data, digits_target, test_size=0.2, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(y_train.shape) == 2 and y_train.shape[0] == len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ottovoncwim\\Desktop\\ottovoncwim\\MIPT\\sem_1\\ML_basic\\ml-course\\homeworks\\assignment0_04_tree\\tree.py:42: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probas = np.sum(y,axis=0)/y.shape[0]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:180: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree is maked\n",
      "0.8638888888888889\n"
     ]
    }
   ],
   "source": [
    "class_estimator = DecisionTree(max_depth=10, criterion_name='gini', debug=True)\n",
    "class_estimator.fit(X_train, y_train)\n",
    "ans = class_estimator.predict(X_test)\n",
    "accuracy_gini = accuracy_score(y_test, ans)\n",
    "print(accuracy_gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([81, 24, 40, 24, 56, 25, 48, 44, 14,  4], dtype=int64))"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(ans, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = np.array([0.09027778, 0.09236111, 0.08333333, 0.09583333, 0.11944444,\n",
    "       0.13888889, 0.09930556, 0.09444444, 0.08055556, 0.10555556])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ottovoncwim\\Desktop\\ottovoncwim\\MIPT\\sem_1\\ML_basic\\ml-course\\homeworks\\assignment0_04_tree\\tree.py:22: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probas = np.sum(y,axis=0)/y.shape[0]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:180: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0.   0.25 0.5  0.   0.   0.   0.25 0.   0.   0.  ]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "0.8805555555555555\n"
     ]
    }
   ],
   "source": [
    "class_estimator = DecisionTree(max_depth=10, criterion_name='entropy')\n",
    "class_estimator.fit(X_train, y_train)\n",
    "ans = class_estimator.predict(X_test)\n",
    "accuracy_entropy = accuracy_score(y_test, ans)\n",
    "print(accuracy_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Temp/ipykernel_2924/1758073761.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32massert\u001b[0m  \u001b[1;36m0.84\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0maccuracy_gini\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32massert\u001b[0m  \u001b[1;36m0.86\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0maccuracy_entropy\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mreference\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1e-3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert  0.84 < accuracy_gini < 0.9\n",
    "assert  0.86 < accuracy_entropy < 0.9\n",
    "assert np.sum(np.abs(class_estimator.predict_proba(X_test).mean(axis=0) - reference)) < 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08611111, 0.09236111, 0.08194444, 0.09166667, 0.11666667,\n",
       "       0.13888889, 0.10347222, 0.1       , 0.08333333, 0.10555556])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_estimator.predict_proba(X_test).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use 5-fold cross validation (`GridSearchCV`) to find optimal values for `max_depth` and `criterion` hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth': range(3,11), 'criterion_name': ['gini', 'entropy']}\n",
    "gs = GridSearchCV(DecisionTree(), param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert gs.best_params_['criterion_name'] == 'entropy'\n",
    "assert 6 < gs.best_params_['max_depth'] < 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.title(\"The dependence of quality on the depth of the tree\")\n",
    "plt.plot(np.arange(3,11), gs.cv_results_['mean_test_score'][:8], label='Gini')\n",
    "plt.plot(np.arange(3,11), gs.cv_results_['mean_test_score'][8:], label='Entropy')\n",
    "plt.legend(fontsize=11, loc=1)\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "regr_data = load_boston().data\n",
    "regr_target = load_boston().target[:, None] # to make the targets consistent with our model interfaces\n",
    "RX_train, RX_test, Ry_train, Ry_test = train_test_split(regr_data, regr_target, test_size=0.2, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.08392156862745\n"
     ]
    }
   ],
   "source": [
    "regressor = DecisionTree(max_depth=10, criterion_name='mad_median')\n",
    "regressor.fit(RX_train, Ry_train)\n",
    "predictions_mad = regressor.predict(RX_test)\n",
    "mse_mad = mean_squared_error(Ry_test, predictions_mad)\n",
    "print(mse_mad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ottovoncwim\\Desktop\\ottovoncwim\\MIPT\\sem_1\\ML_basic\\ml-course\\homeworks\\assignment0_04_tree\\tree.py:62: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return y.var()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:221: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\ottovoncwim\\Desktop\\ottovoncwim\\MIPT\\sem_1\\ML_basic\\ml-course\\homeworks\\assignment0_04_tree\\tree.py:280: RuntimeWarning: Mean of empty slice.\n",
      "  value = y_subset.mean()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.123137254901962\n"
     ]
    }
   ],
   "source": [
    "regressor = DecisionTree(max_depth=10, criterion_name='variance')\n",
    "regressor.fit(RX_train, Ry_train)\n",
    "predictions_mad = regressor.predict(RX_test)\n",
    "mse_var = mean_squared_error(Ry_test, predictions_mad)\n",
    "print(mse_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Temp/ipykernel_2924/3074742550.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[1;36m9\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmse_mad\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32massert\u001b[0m \u001b[1;36m8\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmse_var\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 9 < mse_mad < 20\n",
    "assert 8 < mse_var < 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_R = {'max_depth': range(2,9), 'criterion_name': ['variance', 'mad_median']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_R = GridSearchCV(DecisionTree(), param_grid=param_grid_R, cv=5, scoring='neg_mean_squared_error', n_jobs=-2)\n",
    "gs_R.fit(RX_train, Ry_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_R.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert gs_R.best_params_['criterion_name'] == 'mad_median'\n",
    "assert 3 < gs_R.best_params_['max_depth'] < 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_scores = gs_R.cv_results_['mean_test_score'][:7]\n",
    "mad_scores = gs_R.cv_results_['mean_test_score'][7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.title(\"The dependence of neg_mse on the depth of the tree\")\n",
    "plt.plot(np.arange(2,9), var_scores, label='variance')\n",
    "plt.plot(np.arange(2,9), mad_scores, label='mad_median')\n",
    "plt.legend(fontsize=11, loc=1)\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel('neg_mse')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
